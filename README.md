## ğŸ¤– Multimodel Chatbot
---
A full-stack Conversational Chatbot and Text Generation Service built using LangChain, LlamaIndex, and FastAPI, featuring a Streamlit UI.
The entire solution is containerized with Docker and deployed on AWS EC2 for scalable cloud-based inference.

ğŸš€ Features
---
* ğŸ’¬ Conversational chatbot UI powered by Streamlit
* ğŸ§  Toggle between LangChain and LlamaIndex backend APIs
* âš¡ï¸ FastAPI microservices for each framework
	* Port 8000 â†’ LangChain
	* Port 8001 â†’ LlamaIndex
* ğŸ³ Single Docker container runs both APIs + Streamlit UI
* ğŸ” Secure API key management via .streamlit/secrets.toml
* â˜ï¸ Fully deployed on AWS EC2 with public endpoint
---

ğŸ§© Technology Stack
---

<img width="409" height="391" alt="image" src="https://github.com/user-attachments/assets/441689c4-7ce8-4d88-adb9-8aaaadbc5137" />



ğŸ§± Project Structure
---

â”œâ”€â”€ app.py                  # Streamlit frontend with model switch

â”œâ”€â”€ lang_chat.py            # FastAPI app for LangChain

â”œâ”€â”€ llamaindex_chat.py      # FastAPI app for LlamaIndex

â”œâ”€â”€ requirements.txt        # Dependencies

â”œâ”€â”€ Dockerfile              # Container setup (Streamlit + APIs)

â”œâ”€â”€ .streamlit/

â”‚   â””â”€â”€ secrets.toml        # Stores API keys securely

â””â”€â”€ README.md               # Documentation

---

âš™ï¸ Setup & Local Run
---

1ï¸âƒ£ Add Your API Key
Create .streamlit/secrets.toml and include:

OPENAI_API_KEY = "YOUR_API_KEY"

Or

You can keep your key details in .env file

2ï¸âƒ£ Install Requirements
pip install -r requirements.txt

3ï¸âƒ£ Run Locally
python lang_chat.py    # Runs LangChain API on port 8000
python llamaindex_chat.py  # Runs LlamaIndex API on port 8001
streamlit run app.py   # Runs Streamlit UI on port 8501

Access at ğŸ‘‰ http://localhost:8501

ğŸ³ Docker Deployment
---

Build Image
```
docker build -t ai-frameworks-chatbot .
```
Run Container
```
docker run -d -p 8501:8501 -p 8000:8000 -p 8001:8001 ai-frameworks-chatbot
```
Then open your browser at
ğŸ‘‰ http://localhost:8501

â˜ï¸ AWS EC2 Deployment (Free Tier Eligible)
---
* Launch an Ubuntu 24.04 EC2 Instance (t2.micro)
* SSH into instance
* Install Docker
* sudo apt update && sudo apt install docker.io -y
* Copy project files using WinSCP or git clone
* Build & Run Docker
	* docker build -t ai-frameworks-chatbot .
	* docker run -d -p 8501:8501 -p 8000:8000 -p 8001:8001 ai-frameworks-chatbot
* Add Inbound Rules to Security Group
* TCP 22 â†’ SSH (Your IP only)
* TCP 8501, 8000, 8001 â†’ 0.0.0.0/0
* 
âœ… Access at:
http://:8501

---

ğŸ§  Technical Architecture
---
ğŸ“˜ Architecture Overview
Below is the architecture representing:

* Streamlit UI
* LangChain & LlamaIndex FastAPI backends
* Docker container orchestration
* AWS EC2 deployment layer

<img width="1224" height="690" alt="image" src="https://github.com/user-attachments/assets/dd1280f6-35a0-4f66-9a18-b61cf1ae4781" />


ğŸ” Security Notes
---
âœ… API Keys are never hardcoded (stored in .streamlit/secrets.toml or you can keep in .env file)

âœ… AWS-level network security (controlled inbound rules)
